[2024-11-23T07:14:13.265+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model permission to 509
[2024-11-23T07:14:13.266+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model'
[2024-11-23T07:14:13.297+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model permission to 509
[2024-11-23T07:14:13.298+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model'
[2024-11-23T07:14:13.322+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: model_training_pipeline.train_model manual__2024-11-23T07:14:08.708663+00:00 [queued]>
[2024-11-23T07:14:13.331+0000] {taskinstance.py:1159} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: model_training_pipeline.train_model manual__2024-11-23T07:14:08.708663+00:00 [queued]>
[2024-11-23T07:14:13.331+0000] {taskinstance.py:1361} INFO - Starting attempt 1 of 2
[2024-11-23T07:14:13.346+0000] {taskinstance.py:1382} INFO - Executing <Task(PythonOperator): train_model> on 2024-11-23 07:14:08.708663+00:00
[2024-11-23T07:14:13.359+0000] {standard_task_runner.py:57} INFO - Started process 20784 to run task
[2024-11-23T07:14:13.361+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'model_training_pipeline', 'train_model', 'manual__2024-11-23T07:14:08.708663+00:00', '--job-id', '382', '--raw', '--subdir', 'DAGS_FOLDER/model_training_pipeline_dag/model_training_dag.py', '--cfg-path', '/tmp/tmp0cut6an7']
[2024-11-23T07:14:13.364+0000] {standard_task_runner.py:85} INFO - Job 382: Subtask train_model
[2024-11-23T07:14:13.407+0000] {logging_mixin.py:151} INFO - Changing /opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model permission to 509
[2024-11-23T07:14:13.408+0000] {logging_mixin.py:151} INFO - Failed to change /opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model permission to 509: [Errno 1] Operation not permitted: '/opt/***/logs/dag_id=model_training_pipeline/run_id=manual__2024-11-23T07:14:08.708663+00:00/task_id=train_model'
[2024-11-23T07:14:13.409+0000] {task_command.py:415} INFO - Running <TaskInstance: model_training_pipeline.train_model manual__2024-11-23T07:14:08.708663+00:00 [running]> on host 2445c017a334
[2024-11-23T07:14:13.485+0000] {taskinstance.py:1660} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='model_training_pipeline' AIRFLOW_CTX_TASK_ID='train_model' AIRFLOW_CTX_EXECUTION_DATE='2024-11-23T07:14:08.708663+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2024-11-23T07:14:08.708663+00:00'
[2024-11-23T07:16:47.172+0000] {logging_mixin.py:151} INFO - Data has been normalised
[2024-11-23T07:16:47.860+0000] {logging_mixin.py:151} WARNING - 2024/11/23 07:16:47 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.
The git executable must be specified in one of the following ways:
    - be included in your $PATH
    - be set via $GIT_PYTHON_GIT_EXECUTABLE
    - explicitly set via git.refresh(<full-path-to-git-executable>)

All git commands will error until this is rectified.

This initial message can be silenced or aggravated in the future by setting the
$GIT_PYTHON_REFRESH environment variable. Use one of the following values:
    - quiet|q|silence|s|silent|none|n|0: for no message or exception
    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)
    - error|e|exception|raise|r|2: for a raised exception

Example:
    export GIT_PYTHON_REFRESH=quiet
[2024-11-23T07:16:48.120+0000] {logging_mixin.py:151} INFO -  X_train columns : Index(['price_heating_oil ($/GAL)', 'imports', 'lng_imports',
       'natural_gas_rigs_in_operation', 'price_1day_lag ($/MMBTU)',
       'price_2day_lag ($/MMBTU)', 'price_3day_lag ($/MMBTU)',
       'heating_oil_natural_gas_price_ratio',
       '7day_ew_volatility price ($/MMBTU)',
       '14day_ew_volatility price ($/MMBTU)',
       '30day_ew_volatility price ($/MMBTU)',
       '60day_ew_volatility price ($/MMBTU)',
       '7day_rolling_average price ($/MMBTU)',
       '14day_rolling_average price ($/MMBTU)',
       '30day_rolling_average price ($/MMBTU)',
       '7day_rolling_median price ($/MMBTU)',
       '14day_rolling_median price ($/MMBTU)',
       '30day_rolling_median price ($/MMBTU)',
       'total_consumption_total_underground_storage_ratio', 'is_dec_or_jan',
       'hdd_max', 'cdd_max', 'min_tavg', 'max_tavg', 'max_abs_tavg_diff',
       'max_abs_tavg_diff_relative_to_daily_median'],
      dtype='object')
[2024-11-23T07:16:48.130+0000] {logging_mixin.py:151} INFO -  Null values by column: price_heating_oil ($/GAL)                            0
imports                                              0
lng_imports                                          0
natural_gas_rigs_in_operation                        0
price_1day_lag ($/MMBTU)                             0
price_2day_lag ($/MMBTU)                             0
price_3day_lag ($/MMBTU)                             0
heating_oil_natural_gas_price_ratio                  0
7day_ew_volatility price ($/MMBTU)                   0
14day_ew_volatility price ($/MMBTU)                  0
30day_ew_volatility price ($/MMBTU)                  0
60day_ew_volatility price ($/MMBTU)                  0
7day_rolling_average price ($/MMBTU)                 0
14day_rolling_average price ($/MMBTU)                0
30day_rolling_average price ($/MMBTU)                0
7day_rolling_median price ($/MMBTU)                  0
14day_rolling_median price ($/MMBTU)                 0
30day_rolling_median price ($/MMBTU)                 0
total_consumption_total_underground_storage_ratio    0
is_dec_or_jan                                        0
hdd_max                                              0
cdd_max                                              0
min_tavg                                             0
max_tavg                                             0
max_abs_tavg_diff                                    0
max_abs_tavg_diff_relative_to_daily_median           0
dtype: int64
[2024-11-23T07:16:48.130+0000] {logging_mixin.py:151} INFO - X_train shape: (168220, 26)
[2024-11-23T07:16:48.131+0000] {logging_mixin.py:151} INFO - X_test shape: (33644, 26)
[2024-11-23T07:16:48.151+0000] {logging_mixin.py:151} INFO - Batch shape: (128, 30, 26), (128,)
[2024-11-23T07:16:48.244+0000] {logging_mixin.py:151} INFO - Epoch 1/150
[2024-11-23T07:16:51.710+0000] {logging_mixin.py:151} WARNING - 2024/11/23 07:16:51 INFO mlflow.tracking._tracking_service.client: üèÉ View run GRU_7_day_horizon_30_20241123 at: http://mlflow:5000/#/experiments/1/runs/1b53a89e806f4992b6829c0882aa4a2c.
[2024-11-23T07:16:51.711+0000] {logging_mixin.py:151} WARNING - 2024/11/23 07:16:51 INFO mlflow.tracking._tracking_service.client: üß™ View experiment at: http://mlflow:5000/#/experiments/1.
[2024-11-23T07:16:51.771+0000] {taskinstance.py:1943} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/model_training_pipeline_dag/train_model.py", line 74, in train_model
    Model.train_model(x_train=X_train, y_train=y_train, x_test=X_test, y_test=y_test, time_steps=30, experiment_id=experiment_id, forecast_horizon=7, batch_size=128)
  File "/opt/airflow/dags/modelling/model.py", line 56, in train_model
    model.fit(train_gen, epochs=150, batch_size=batch_size, validation_data=test_gen, verbose=2,
  File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 70, in error_handler
    raise e.with_traceback(filtered_tb) from None
  File "/home/airflow/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py", line 53, in quick_execute
    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,
tensorflow.python.framework.errors_impl.InvalidArgumentError: Graph execution error:

Detected at node 'while/BiasAdd' defined at (most recent call last):
    File "/home/airflow/.local/bin/airflow", line 8, in <module>
      sys.exit(main())
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/__main__.py", line 60, in main
      args.func(args)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 113, in wrapper
      return f(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/providers_configuration_loader.py", line 56, in wrapped_function
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/scheduler_command.py", line 85, in scheduler
      _run_scheduler_job(job_runner, skip_serve_logs=args.skip_serve_logs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
      run_job(job=job_runner.job, execute_callable=job_runner._execute)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
      return func(*args, session=session, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 289, in run_job
      return execute_job(job, execute_callable=execute_callable)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 318, in execute_job
      ret = execute_callable()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job_runner.py", line 838, in _execute
      self.job.executor.start()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 367, in start
      self.impl.start()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 308, in start
      worker.start()
    File "/usr/local/lib/python3.8/multiprocessing/process.py", line 121, in start
      self._popen = self._Popen(self)
    File "/usr/local/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
      return _default_context.get_context().Process._Popen(process_obj)
    File "/usr/local/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
      return Popen(process_obj)
    File "/usr/local/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
      self._launch(process_obj)
    File "/usr/local/lib/python3.8/multiprocessing/popen_fork.py", line 75, in _launch
      code = process_obj._bootstrap(parent_sentinel=child_r)
    File "/usr/local/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
      self.run()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 74, in run
      return super().run()
    File "/usr/local/lib/python3.8/multiprocessing/process.py", line 108, in run
      self._target(*self._args, **self._kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 198, in do_work
      self.execute_work(key=key, command=command)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 91, in execute_work
      state = self._execute_work_in_fork(command)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 131, in _execute_work_in_fork
      args.func(args)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 113, in wrapper
      return f(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 430, in task_run
      task_return_code = _run_task_by_selected_method(args, _dag, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 208, in _run_task_by_selected_method
      return _run_task_by_local_task_job(args, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 270, in _run_task_by_local_task_job
      ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
      return func(*args, session=session, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 289, in run_job
      return execute_job(job, execute_callable=execute_callable)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 318, in execute_job
      ret = execute_callable()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/local_task_job_runner.py", line 159, in _execute
      self.task_runner.start()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 45, in start
      self.process = self._start_by_fork()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 97, in _start_by_fork
      ret = args.func(args, dag=self.dag)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 113, in wrapper
      return f(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 430, in task_run
      task_return_code = _run_task_by_selected_method(args, _dag, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 210, in _run_task_by_selected_method
      return _run_raw_task(args, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 289, in _run_raw_task
      return ti._run_raw_task(
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
      return func(*args, session=session, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1518, in _run_raw_task
      self._execute_task_with_callbacks(context, test_mode, session=session)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1679, in _execute_task_with_callbacks
      result = self._execute_task(context, task_orig)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1750, in _execute_task
      result = execute_callable(context=context)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
      return_value = self.execute_callable()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
      return self.python_callable(*self.op_args, **self.op_kwargs)
    File "/opt/airflow/dags/model_training_pipeline_dag/train_model.py", line 74, in train_model
      Model.train_model(x_train=X_train, y_train=y_train, x_test=X_test, y_test=y_test, time_steps=30, experiment_id=experiment_id, forecast_horizon=7, batch_size=128)
    File "/opt/airflow/dags/modelling/model.py", line 56, in train_model
      model.fit(train_gen, epochs=150, batch_size=batch_size, validation_data=test_gen, verbose=2,
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1742, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1338, in train_function
      return step_function(self, iterator)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1322, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1303, in run_step
      outputs = model.train_step(data)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1080, in train_step
      y_pred = self(x, training=True)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 569, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/base_layer.py", line 1150, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/sequential.py", line 405, in call
      return super().call(inputs, training=training, mask=mask)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/base_rnn.py", line 556, in __call__
      return super().__call__(inputs, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/base_layer.py", line 1150, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 670, in call
      last_output, outputs, runtime, states = self._defun_gru_call(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 902, in _defun_gru_call
      ) = gru_with_backend_selection(**normal_gru_kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 1297, in gru_with_backend_selection
      last_output, outputs, new_h, runtime = defun_standard_gru(**params)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 994, in standard_gru
      last_output, outputs, new_states = backend.rnn(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/backend.py", line 5170, in rnn
      final_outputs = tf.compat.v1.while_loop(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/backend.py", line 5149, in _step
      output, new_states = step_function(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 975, in step
      matrix_x = backend.bias_add(matrix_x, input_bias)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/backend.py", line 6884, in bias_add
      return tf.nn.bias_add(x, bias, data_format="NHWC")
Node: 'while/BiasAdd'
Matrix size-incompatible: In[0]: [128,26], In[1]: [25,96]
	 [[{{node while/BiasAdd}}]]
	 [[sequential/gru/PartitionedCall]] [Op:__inference_train_function_5922]
[2024-11-23T07:16:51.791+0000] {taskinstance.py:1400} INFO - Marking task as UP_FOR_RETRY. dag_id=model_training_pipeline, task_id=train_model, execution_date=20241123T071408, start_date=20241123T071413, end_date=20241123T071651
[2024-11-23T07:16:51.808+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 382 for task train_model (Graph execution error:

Detected at node 'while/BiasAdd' defined at (most recent call last):
    File "/home/airflow/.local/bin/airflow", line 8, in <module>
      sys.exit(main())
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/__main__.py", line 60, in main
      args.func(args)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 113, in wrapper
      return f(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/providers_configuration_loader.py", line 56, in wrapped_function
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/scheduler_command.py", line 85, in scheduler
      _run_scheduler_job(job_runner, skip_serve_logs=args.skip_serve_logs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/scheduler_command.py", line 47, in _run_scheduler_job
      run_job(job=job_runner.job, execute_callable=job_runner._execute)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
      return func(*args, session=session, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 289, in run_job
      return execute_job(job, execute_callable=execute_callable)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 318, in execute_job
      ret = execute_callable()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/scheduler_job_runner.py", line 838, in _execute
      self.job.executor.start()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 367, in start
      self.impl.start()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 308, in start
      worker.start()
    File "/usr/local/lib/python3.8/multiprocessing/process.py", line 121, in start
      self._popen = self._Popen(self)
    File "/usr/local/lib/python3.8/multiprocessing/context.py", line 224, in _Popen
      return _default_context.get_context().Process._Popen(process_obj)
    File "/usr/local/lib/python3.8/multiprocessing/context.py", line 277, in _Popen
      return Popen(process_obj)
    File "/usr/local/lib/python3.8/multiprocessing/popen_fork.py", line 19, in __init__
      self._launch(process_obj)
    File "/usr/local/lib/python3.8/multiprocessing/popen_fork.py", line 75, in _launch
      code = process_obj._bootstrap(parent_sentinel=child_r)
    File "/usr/local/lib/python3.8/multiprocessing/process.py", line 315, in _bootstrap
      self.run()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 74, in run
      return super().run()
    File "/usr/local/lib/python3.8/multiprocessing/process.py", line 108, in run
      self._target(*self._args, **self._kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 198, in do_work
      self.execute_work(key=key, command=command)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 91, in execute_work
      state = self._execute_work_in_fork(command)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/executors/local_executor.py", line 131, in _execute_work_in_fork
      args.func(args)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 113, in wrapper
      return f(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 430, in task_run
      task_return_code = _run_task_by_selected_method(args, _dag, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 208, in _run_task_by_selected_method
      return _run_task_by_local_task_job(args, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 270, in _run_task_by_local_task_job
      ret = run_job(job=job_runner.job, execute_callable=job_runner._execute)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
      return func(*args, session=session, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 289, in run_job
      return execute_job(job, execute_callable=execute_callable)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/job.py", line 318, in execute_job
      ret = execute_callable()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/jobs/local_task_job_runner.py", line 159, in _execute
      self.task_runner.start()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 45, in start
      self.process = self._start_by_fork()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/task/task_runner/standard_task_runner.py", line 97, in _start_by_fork
      ret = args.func(args, dag=self.dag)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/cli_config.py", line 49, in command
      return func(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/cli.py", line 113, in wrapper
      return f(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 430, in task_run
      task_return_code = _run_task_by_selected_method(args, _dag, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 210, in _run_task_by_selected_method
      return _run_raw_task(args, ti)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/cli/commands/task_command.py", line 289, in _run_raw_task
      return ti._run_raw_task(
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/utils/session.py", line 77, in wrapper
      return func(*args, session=session, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1518, in _run_raw_task
      self._execute_task_with_callbacks(context, test_mode, session=session)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1679, in _execute_task_with_callbacks
      result = self._execute_task(context, task_orig)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/taskinstance.py", line 1750, in _execute_task
      result = execute_callable(context=context)
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 192, in execute
      return_value = self.execute_callable()
    File "/home/airflow/.local/lib/python3.8/site-packages/airflow/operators/python.py", line 209, in execute_callable
      return self.python_callable(*self.op_args, **self.op_kwargs)
    File "/opt/airflow/dags/model_training_pipeline_dag/train_model.py", line 74, in train_model
      Model.train_model(x_train=X_train, y_train=y_train, x_test=X_test, y_test=y_test, time_steps=30, experiment_id=experiment_id, forecast_horizon=7, batch_size=128)
    File "/opt/airflow/dags/modelling/model.py", line 56, in train_model
      model.fit(train_gen, epochs=150, batch_size=batch_size, validation_data=test_gen, verbose=2,
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1742, in fit
      tmp_logs = self.train_function(iterator)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1338, in train_function
      return step_function(self, iterator)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1322, in step_function
      outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1303, in run_step
      outputs = model.train_step(data)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 1080, in train_step
      y_pred = self(x, training=True)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/training.py", line 569, in __call__
      return super().__call__(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/base_layer.py", line 1150, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/sequential.py", line 405, in call
      return super().call(inputs, training=training, mask=mask)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/functional.py", line 512, in call
      return self._run_internal_graph(inputs, training=training, mask=mask)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/functional.py", line 669, in _run_internal_graph
      outputs = node.layer(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/base_rnn.py", line 556, in __call__
      return super().__call__(inputs, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 65, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/engine/base_layer.py", line 1150, in __call__
      outputs = call_fn(inputs, *args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py", line 96, in error_handler
      return fn(*args, **kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 670, in call
      last_output, outputs, runtime, states = self._defun_gru_call(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 902, in _defun_gru_call
      ) = gru_with_backend_selection(**normal_gru_kwargs)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 1297, in gru_with_backend_selection
      last_output, outputs, new_h, runtime = defun_standard_gru(**params)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 994, in standard_gru
      last_output, outputs, new_states = backend.rnn(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/backend.py", line 5170, in rnn
      final_outputs = tf.compat.v1.while_loop(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/backend.py", line 5149, in _step
      output, new_states = step_function(
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/layers/rnn/gru.py", line 975, in step
      matrix_x = backend.bias_add(matrix_x, input_bias)
    File "/home/airflow/.local/lib/python3.8/site-packages/keras/src/backend.py", line 6884, in bias_add
      return tf.nn.bias_add(x, bias, data_format="NHWC")
Node: 'while/BiasAdd'
Matrix size-incompatible: In[0]: [128,26], In[1]: [25,96]
	 [[{{node while/BiasAdd}}]]
	 [[sequential/gru/PartitionedCall]] [Op:__inference_train_function_5922]; 20784)
[2024-11-23T07:16:51.895+0000] {local_task_job_runner.py:228} INFO - Task exited with return code 1
[2024-11-23T07:16:51.914+0000] {taskinstance.py:2784} INFO - 0 downstream tasks scheduled from follow-on schedule check
